{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project_BoredomDetection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMncDU49c2B2ML3q9nkoJqm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"koRQPuZwwYo2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1596512335342,"user_tz":420,"elapsed":31467,"user":{"displayName":"Nashila Jahan","photoUrl":"","userId":"06335545168671300261"}},"outputId":"162fedb8-fb1f-41e7-e263-bb8581b2b8c3"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","os.chdir('drive/My Drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5ZFRHRmJw8rR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":986},"executionInfo":{"status":"ok","timestamp":1595226882046,"user_tz":420,"elapsed":1518,"user":{"displayName":"Nashila Jahan","photoUrl":"","userId":"06335545168671300261"}},"outputId":"c47b5e62-4c83-4b79-dfa1-e3c242018cca"},"source":["#!tar -zxvf aff_wild_videos_annotations_bboxes_landmarks.tar.gz\n","#os.chdir('/content/drive/My Drive/data_aff_wild/landmarks/')\n","\n","#!tar -zxvf test.tar.gz\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test/103/454.pts\n","test/267/2232.pts\n","test/381/381.pts\n","test/119/2800.pts\n","test/244/52.pts\n","test/281/6804.pts\n","test/336/1893.pts\n","test/241/498.pts\n","test/194/3161.pts\n","test/204/3920.pts\n","test/241/1168.pts\n","test/147/12226.pts\n","test/307/1427.pts\n","test/147/6864.pts\n","test/274/1044.pts\n","test/139/2734.pts\n","test/103/18576.pts\n","test/204/3.pts\n","test/268/2173.pts\n","test/197/42.pts\n","test/119/436.pts\n","test/357/732.pts\n","test/103/5527.pts\n","test/165/1539.pts\n","test/268/3376.pts\n","test/139/3937.pts\n","test/375/798.pts\n","test/304/1737.pts\n","test/367/673.pts\n","test/434/2711.pts\n","test/322/447.pts\n","test/416/4909.pts\n","test/159/1097.pts\n","test/265/2483.pts\n","test/380/691.pts\n","test/199/1356.pts\n","test/450/5594.pts\n","test/450/1811.pts\n","test/102/764.pts\n","test/147/990.pts\n","test/284/2476.pts\n","test/307/1583.pts\n","test/103/4480.pts\n","test/416/3862.pts\n","test/147/5049.pts\n","test/103/8410.pts\n","test/119/592.pts\n","test/304/1893.pts\n","test/265/3686.pts\n","test/103/10863.pts\n","test/450/6797.pts\n","test/165/1695.pts\n","test/209/880.pts\n","test/311/816.pts\n","test/284/3679.pts\n","test/281/2786.pts\n","^C\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q9NzgIWf7G-2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596512344651,"user_tz":420,"elapsed":1010,"user":{"displayName":"Nashila Jahan","photoUrl":"","userId":"06335545168671300261"}}},"source":["DATA_DIR = \"data_aff_wild\"\n","ANNOTATION_TRAIN_DIR = os.path.join(DATA_DIR, \"annotations/train\")\n","AROUSAL_TRAIN_DIR = os.path.join(DATA_DIR, \"annotations/train/arousal\")\n","VALENCE_TRAIN_DIR = os.path.join(DATA_DIR, \"annotations/train/valence\")\n","AROUSAL_TRAIN_FILES = os.path.join(AROUSAL_TRAIN_DIR, \"*.txt\")\n","VALENCE_TRAIN_FILES = os.path.join(VALENCE_TRAIN_DIR, \"*.txt\")\n","\n","#BBOXES_TRAIN_DIR = os.path.join(DATA_DIR, \"bboxs/train\")\n","#LANDMARKS_TRAIN_DIR = os.path.join(DATA_DIR, \"landmarks/train\")\n","VIDEOS_TRAIN_DIR = os.path.join(DATA_DIR, \"videos/train\")\n","VIDEOS_TEST_DIR = os.path.join(DATA_DIR, \"videos/test\")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"coLHE1CK7eM1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1596512366967,"user_tz":420,"elapsed":15214,"user":{"displayName":"Nashila Jahan","photoUrl":"","userId":"06335545168671300261"}},"outputId":"08355057-f8b4-419b-cae6-ac76e7df5216"},"source":["\"\"\"\n","Sanity: if the number of annotations same as the number of frames.\n","\"\"\"\n","import os\n","\n","import numpy as np\n","import cv2\n","os.chdir('/content/drive/My Drive/')\n","\n","\n","def count_frame(path: str) -> int:\n","    video_obj = cv2.VideoCapture(path)\n","    frame_counter = 0\n","    success = 1\n","    while success:\n","        success, _ = video_obj.read()\n","        frame_counter += 1\n","    return frame_counter - 1\n","\n","def count_lines(path: str) -> int:\n","    line_counter = 0\n","    with open(path) as f:\n","        for _ in f:\n","            line_counter += 1\n","    return line_counter\n","num_frames = count_frame(os.path.join(VIDEOS_TRAIN_DIR, \"105.avi\"))\n","num_annotations = count_lines(os.path.join(AROUSAL_TRAIN_DIR, \"105.txt\"))\n","print(num_frames)\n","print(num_annotations)\n","assert num_frames == num_annotations"],"execution_count":3,"outputs":[{"output_type":"stream","text":["10076\n","10076\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QuhwpMm17pND","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596513751568,"user_tz":420,"elapsed":1275377,"user":{"displayName":"Nashila Jahan","photoUrl":"","userId":"06335545168671300261"}}},"source":["\"\"\"\n","Filter frames by arousal and valence and save to a folder.\n","\"\"\"\n","import glob\n","from collections import defaultdict\n","\n","import cv2\n","\n","BORED = (-0.34, -0.78)\n","DROOPY = (-0.32, -0.96)\n","TIRED = (-0.02, -0.99)\n","SLEEPY = (0.02, -0.99)\n","EMOTIONS = [BORED, DROOPY, TIRED, SLEEPY]\n","\n","def is_bored(valence: float, \n","             arousal: float, \n","             radius: float=0.1) -> bool:\n","    \"\"\"\n","    Defined bored in valence, arousal. See Fig. 1 in https://arxiv.org/pdf/1804.10938.pdf.\n","    \"\"\"\n","    is_bored = False\n","    for (emotion_valence, emotion_arousal) in EMOTIONS:\n","        with_in_radius = (emotion_valence - radius <= valence <= emotion_valence + radius and \n","            emotion_arousal - radius <= arousal <= emotion_arousal + radius)\n","        is_bored = is_bored or with_in_radius\n","    return is_bored\n","\n","def get_video_path(video_id: str):\n","    mp4_path = os.path.join(VIDEOS_TRAIN_DIR, video_id + \".mp4\")\n","    avi_path = os.path.join(VIDEOS_TRAIN_DIR, video_id + \".avi\")\n","    if os.path.isfile(mp4_path):\n","        return mp4_path\n","    if os.path.isfile(avi_path):\n","        return avi_path\n","    raise ValueError(\"Video {} does not exist\".format(video_id))\n","\n","def create_candidates(output_dir=\"candidates\", radius: float=0.2) -> str:\n","    candidate_frames = defaultdict(set)\n","    total_count = 0\n","    bored_count = 0\n","    for arousal_file, valence_file in zip(sorted(glob.glob(AROUSAL_TRAIN_FILES)), sorted(glob.glob(VALENCE_TRAIN_FILES))):\n","        video_id = os.path.splitext(os.path.basename(arousal_file))[0] # eg. file_id = 105\n","        arousal_file = open(arousal_file, 'r')\n","        valence_file = open(valence_file, 'r')\n","        arousal_values = [float(line) for line in arousal_file.readlines()]\n","        valence_values = [float(line) for line in valence_file.readlines()]\n","        for frame_id, (valence_value, arousal_value) in enumerate(zip(valence_values, arousal_values)):\n","            total_count += 1\n","            if is_bored(valence_value, arousal_value, radius=radius):\n","                bored_count += 1\n","                candidate_frames[video_id].add(frame_id)\n","\n","    # Create frame file for each candidate frames.\n","    output_dir_bored = os.path.join(output_dir, str(radius), \"non_productive\")\n","    output_dir_non_bored = os.path.join(output_dir, str(radius), \"productive\")\n","    \n","    os.makedirs(output_dir, exist_ok=True)\n","    os.makedirs(output_dir_bored, exist_ok=True)\n","    os.makedirs(output_dir_non_bored, exist_ok=True)\n","    for video_id, candidate_frames in candidate_frames.items():\n","        video_file = get_video_path(video_id)\n","        video_obj = cv2.VideoCapture(video_file)\n","        frame_id = 0\n","        success = True\n","        while success:\n","            success, frame = video_obj.read()\n","            if success:\n","                if frame_id in candidate_frames:\n","                    cv2.imwrite(os.path.join(output_dir_bored, \"{}_{}.jpg\".format(video_id, frame_id)),\n","                                frame)\n","                else:\n","                    cv2.imwrite(os.path.join(output_dir_non_bored, \"{}_{}.jpg\".format(video_id, frame_id)),\n","                                frame)\n","            frame_id += 1\n","\n","    return candidate_frames, bored_count, total_count\n","    \n","    \n","candidate_frames, bored_count, total_count = create_candidates()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"VF7-PCHO7woN","colab_type":"code","colab":{}},"source":["\"\"\"\n","Radius = 0.3, annotation. Inclusive range.\n","\"\"\"\n","annotations = [\n","    [\"299_448\", \"299_454\"],\n","    [\"305_1712\", \"305_1760\"],\n","    [\"308_247\", \"308_286\"],\n","    [\"312_1289\", \"312_1329\"],\n","    [\"313_324\", \"313_345\"],\n","    [\"313_1276\", \"313_1625\"],\n","    [\"369_680\", \"369_896\"],\n","    [\"377_2034\", \"377_2234\"], \n","    [\"385_244\", \"385_521\"],\n","    [\"386_84\", \"386_128\"],\n","    [\"389_418\", \"389_3404\"],\n","    [\"400_42\", \"400_72\"],\n","    [\"447_929\", \"447_1118\"],\n","    [\"448_1295\", \"448_2571\"]\n","]"],"execution_count":null,"outputs":[]}]}