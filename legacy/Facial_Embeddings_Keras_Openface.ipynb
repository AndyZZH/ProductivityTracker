{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLKOtoiQ8GES"
   },
   "source": [
    "Import the prerequisite libraries\n",
    "We will be importing utils.py from https://github.com/iwantooxxoox/Keras-OpenFace/blob/master/utils.py (available with code) which contains utility functions to create the neural network and load the weights assoiated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PA65el4PwLpi"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kvZgfGn27y32",
    "outputId": "baa76aea-9f5e-4b84-f3d5-1a55064348d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "brzW3LQeB_Ij",
    "outputId": "2a259db3-4232-4f58-9cc3-c8d9287b2618"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Keras-OpenFace'...\n",
      "remote: Enumerating objects: 383, done.\u001b[K\n",
      "remote: Total 383 (delta 0), reused 0 (delta 0), pack-reused 383\u001b[K\n",
      "Receiving objects: 100% (383/383), 109.63 MiB | 27.80 MiB/s, done.\n",
      "Resolving deltas: 100% (74/74), done.\n",
      "Checking out files: 100% (257/257), done.\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/iwantooxxoox/Keras-OpenFace.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "FhDb2t4dACZW",
    "outputId": "b4f1f8c0-8cf2-4a8b-e782-426180f356e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoreML-Convertion.ipynb  gen_emb.pyc\t\t\t  README.md\n",
      "evaluation\t\t Keras-Openface-Accuracy.ipynb\t  Untitled.ipynb\n",
      "exportWeight.lua\t Keras-openface-convertion.ipynb  utils.lua\n",
      "facenet.py\t\t lfw.py\t\t\t\t  utils.py\n",
      "facenet.pyc\t\t lfw.pyc\t\t\t  utils.pyc\n",
      "gen_emb.py\t\t model\t\t\t\t  weights\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#os.chdir('/content/Keras-OpenFace/')\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AXk3CticRdm6"
   },
   "outputs": [],
   "source": [
    "# create new directories under My Drive\n",
    "\n",
    "#os.chdir(\"/content/drive/My Drive/candidates/\")\n",
    "#!cp -r /content/Keras-OpenFace training/\n",
    "os.chdir(\"/content/drive/My Drive/candidates/training/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hkqGy1hTArg_"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "import utils\n",
    "from utils import LRN2D\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "faioi4ypE6XI"
   },
   "outputs": [],
   "source": [
    "myInput = Input(shape=(96, 96, 3))\n",
    "\n",
    "x = ZeroPadding2D(padding=(3, 3), input_shape=(96, 96, 3))(myInput)\n",
    "x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "x = BatchNormalization(axis=3, epsilon=0.00001, name='bn1')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "x = Lambda(LRN2D, name='lrn_1')(x)\n",
    "x = Conv2D(64, (1, 1), name='conv2')(x)\n",
    "x = BatchNormalization(axis=3, epsilon=0.00001, name='bn2')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "x = Conv2D(192, (3, 3), name='conv3')(x)\n",
    "x = BatchNormalization(axis=3, epsilon=0.00001, name='bn3')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Lambda(LRN2D, name='lrn_2')(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "# Inception3a\n",
    "inception_3a_3x3 = Conv2D(96, (1, 1), name='inception_3a_3x3_conv1')(x)\n",
    "inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn1')(inception_3a_3x3)\n",
    "inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n",
    "inception_3a_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3)\n",
    "inception_3a_3x3 = Conv2D(128, (3, 3), name='inception_3a_3x3_conv2')(inception_3a_3x3)\n",
    "inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn2')(inception_3a_3x3)\n",
    "inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n",
    "\n",
    "inception_3a_5x5 = Conv2D(16, (1, 1), name='inception_3a_5x5_conv1')(x)\n",
    "inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn1')(inception_3a_5x5)\n",
    "inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n",
    "inception_3a_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5)\n",
    "inception_3a_5x5 = Conv2D(32, (5, 5), name='inception_3a_5x5_conv2')(inception_3a_5x5)\n",
    "inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn2')(inception_3a_5x5)\n",
    "inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n",
    "\n",
    "inception_3a_pool = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "inception_3a_pool = Conv2D(32, (1, 1), name='inception_3a_pool_conv')(inception_3a_pool)\n",
    "inception_3a_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_pool_bn')(inception_3a_pool)\n",
    "inception_3a_pool = Activation('relu')(inception_3a_pool)\n",
    "inception_3a_pool = ZeroPadding2D(padding=((3, 4), (3, 4)))(inception_3a_pool)\n",
    "\n",
    "inception_3a_1x1 = Conv2D(64, (1, 1), name='inception_3a_1x1_conv')(x)\n",
    "inception_3a_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_1x1_bn')(inception_3a_1x1)\n",
    "inception_3a_1x1 = Activation('relu')(inception_3a_1x1)\n",
    "\n",
    "inception_3a = concatenate([inception_3a_3x3, inception_3a_5x5, inception_3a_pool, inception_3a_1x1], axis=3)\n",
    "\n",
    "# Inception3b\n",
    "inception_3b_3x3 = Conv2D(96, (1, 1), name='inception_3b_3x3_conv1')(inception_3a)\n",
    "inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn1')(inception_3b_3x3)\n",
    "inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n",
    "inception_3b_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3)\n",
    "inception_3b_3x3 = Conv2D(128, (3, 3), name='inception_3b_3x3_conv2')(inception_3b_3x3)\n",
    "inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn2')(inception_3b_3x3)\n",
    "inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n",
    "\n",
    "inception_3b_5x5 = Conv2D(32, (1, 1), name='inception_3b_5x5_conv1')(inception_3a)\n",
    "inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn1')(inception_3b_5x5)\n",
    "inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n",
    "inception_3b_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5)\n",
    "inception_3b_5x5 = Conv2D(64, (5, 5), name='inception_3b_5x5_conv2')(inception_3b_5x5)\n",
    "inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn2')(inception_3b_5x5)\n",
    "inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n",
    "\n",
    "inception_3b_pool = Lambda(lambda x: x**2, name='power2_3b')(inception_3a)\n",
    "inception_3b_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_3b_pool)\n",
    "inception_3b_pool = Lambda(lambda x: x*9, name='mult9_3b')(inception_3b_pool)\n",
    "inception_3b_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_3b')(inception_3b_pool)\n",
    "inception_3b_pool = Conv2D(64, (1, 1), name='inception_3b_pool_conv')(inception_3b_pool)\n",
    "inception_3b_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_pool_bn')(inception_3b_pool)\n",
    "inception_3b_pool = Activation('relu')(inception_3b_pool)\n",
    "inception_3b_pool = ZeroPadding2D(padding=(4, 4))(inception_3b_pool)\n",
    "\n",
    "inception_3b_1x1 = Conv2D(64, (1, 1), name='inception_3b_1x1_conv')(inception_3a)\n",
    "inception_3b_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_1x1_bn')(inception_3b_1x1)\n",
    "inception_3b_1x1 = Activation('relu')(inception_3b_1x1)\n",
    "\n",
    "inception_3b = concatenate([inception_3b_3x3, inception_3b_5x5, inception_3b_pool, inception_3b_1x1], axis=3)\n",
    "\n",
    "# Inception3c\n",
    "inception_3c_3x3 = utils.conv2d_bn(inception_3b,\n",
    "                                   layer='inception_3c_3x3',\n",
    "                                   cv1_out=128,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=256,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(1, 1))\n",
    "\n",
    "inception_3c_5x5 = utils.conv2d_bn(inception_3b,\n",
    "                                   layer='inception_3c_5x5',\n",
    "                                   cv1_out=32,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=64,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(2, 2))\n",
    "\n",
    "inception_3c_pool = MaxPooling2D(pool_size=3, strides=2)(inception_3b)\n",
    "inception_3c_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_3c_pool)\n",
    "\n",
    "inception_3c = concatenate([inception_3c_3x3, inception_3c_5x5, inception_3c_pool], axis=3)\n",
    "\n",
    "#inception 4a\n",
    "inception_4a_3x3 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=192,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_4a_5x5 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_5x5',\n",
    "                                   cv1_out=32,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=64,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(2, 2))\n",
    "\n",
    "inception_4a_pool = Lambda(lambda x: x**2, name='power2_4a')(inception_3c)\n",
    "inception_4a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_4a_pool)\n",
    "inception_4a_pool = Lambda(lambda x: x*9, name='mult9_4a')(inception_4a_pool)\n",
    "inception_4a_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_4a')(inception_4a_pool)\n",
    "inception_4a_pool = utils.conv2d_bn(inception_4a_pool,\n",
    "                                   layer='inception_4a_pool',\n",
    "                                   cv1_out=128,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   padding=(2, 2))\n",
    "inception_4a_1x1 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_4a = concatenate([inception_4a_3x3, inception_4a_5x5, inception_4a_pool, inception_4a_1x1], axis=3)\n",
    "\n",
    "#inception4e\n",
    "inception_4e_3x3 = utils.conv2d_bn(inception_4a,\n",
    "                                   layer='inception_4e_3x3',\n",
    "                                   cv1_out=160,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=256,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(1, 1))\n",
    "inception_4e_5x5 = utils.conv2d_bn(inception_4a,\n",
    "                                   layer='inception_4e_5x5',\n",
    "                                   cv1_out=64,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=128,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(2, 2))\n",
    "inception_4e_pool = MaxPooling2D(pool_size=3, strides=2)(inception_4a)\n",
    "inception_4e_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_4e_pool)\n",
    "\n",
    "inception_4e = concatenate([inception_4e_3x3, inception_4e_5x5, inception_4e_pool], axis=3)\n",
    "\n",
    "#inception5a\n",
    "inception_5a_3x3 = utils.conv2d_bn(inception_4e,\n",
    "                                   layer='inception_5a_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=384,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "\n",
    "inception_5a_pool = Lambda(lambda x: x**2, name='power2_5a')(inception_4e)\n",
    "inception_5a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_5a_pool)\n",
    "inception_5a_pool = Lambda(lambda x: x*9, name='mult9_5a')(inception_5a_pool)\n",
    "inception_5a_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_5a')(inception_5a_pool)\n",
    "inception_5a_pool = utils.conv2d_bn(inception_5a_pool,\n",
    "                                   layer='inception_5a_pool',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_5a_1x1 = utils.conv2d_bn(inception_4e,\n",
    "                                   layer='inception_5a_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "\n",
    "inception_5a = concatenate([inception_5a_3x3, inception_5a_pool, inception_5a_1x1], axis=3)\n",
    "\n",
    "#inception_5b\n",
    "inception_5b_3x3 = utils.conv2d_bn(inception_5a,\n",
    "                                   layer='inception_5b_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=384,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_5b_pool = MaxPooling2D(pool_size=3, strides=2)(inception_5a)\n",
    "inception_5b_pool = utils.conv2d_bn(inception_5b_pool,\n",
    "                                   layer='inception_5b_pool',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_5b_pool = ZeroPadding2D(padding=(1, 1))(inception_5b_pool)\n",
    "\n",
    "inception_5b_1x1 = utils.conv2d_bn(inception_5a,\n",
    "                                   layer='inception_5b_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_5b = concatenate([inception_5b_3x3, inception_5b_pool, inception_5b_1x1], axis=3)\n",
    "\n",
    "av_pool = AveragePooling2D(pool_size=(3, 3), strides=(1, 1))(inception_5b)\n",
    "reshape_layer = Flatten()(av_pool)\n",
    "dense_layer = Dense(128, name='dense_layer')(reshape_layer)\n",
    "norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer')(dense_layer)\n",
    "\n",
    "\n",
    "# Final Model\n",
    "model = Model(inputs=[myInput], outputs=norm_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKFm_KF41syv"
   },
   "outputs": [],
   "source": [
    "# Load weights from csv files (which was exported from Openface torch model)\n",
    "weights = utils.weights\n",
    "weights_dict = utils.load_weights()\n",
    "\n",
    "# Set layer weights of the model\n",
    "for name in weights:\n",
    "  if model.get_layer(name) != None:\n",
    "    model.get_layer(name).set_weights(weights_dict[name])\n",
    "  elif model.get_layer(name) != None:\n",
    "    model.get_layer(name).set_weights(weights_dict[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ayY8lF_lXNES"
   },
   "outputs": [],
   "source": [
    "# save the model in training directory\n",
    "model.save('./model/nn4.small2.lrn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xvH-6QFk2Y7R"
   },
   "source": [
    "The image_to_embedding function generates 128 dimensional image embeddings of all the images stored in the data directory by feed forwarding the images to a trained neural network. Using these embeddings as our dataset we train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gilisSA2CbS"
   },
   "outputs": [],
   "source": [
    "def image_to_embedding(image, model):\n",
    "    #image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_AREA) \n",
    "    image = cv2.resize(image, (96, 96)) \n",
    "    img = image[...,::-1]\n",
    "    img = np.around(np.transpose(img, (0,1,2))/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4zS-7pMI4mqg"
   },
   "outputs": [],
   "source": [
    "labels = {0:'nonproductive',\n",
    "         1:'productive'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8h1z3oOT5Rjo"
   },
   "outputs": [],
   "source": [
    "nonproductive_dir = '/content/drive/My Drive/candidates/0.1/nonproductive/'\n",
    "productive_dir = '/content/drive/My Drive/candidates/0.1/productive/'\n",
    "\n",
    "dir_list = [nonproductive_dir, productive_dir]\n",
    "embeddings = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "kGoZiLEp7RPE",
    "outputId": "0278ddd4-5581-44f5-f92a-157e5cba696e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "48606 48606\n",
      "(48606, 128)\n"
     ]
    }
   ],
   "source": [
    "lbl = 0\n",
    "for directory in dir_list:\n",
    "    for f in os.listdir(directory):\n",
    "        file = directory+'/'+f\n",
    "        img = cv2.imread(file)\n",
    "        embedding = image_to_embedding(img, model)\n",
    "        embeddings.append(embedding)\n",
    "        y.append(lbl)\n",
    "    lbl = lbl + 1\n",
    "\n",
    "print(len(embeddings), len(y))\n",
    "x = np.array(embeddings)\n",
    "x = x.reshape(x.shape[0],128)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B8XlgM-0uei4"
   },
   "outputs": [],
   "source": [
    "# save numpy array as csv file for embeddings and labels generated in the previous step\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "# save to csv file\n",
    "savetxt('embeddings.csv', x, delimiter=',')\n",
    "savetxt('labels.csv', y, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EnnzM3YG1PZB",
    "outputId": "0f4749d1-b784-4739-a32a-0b440424bc38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils import CustomObjectScope\n",
    "with CustomObjectScope({'tf': tf}):\n",
    "  model = load_model('./model/nn4.small2.lrn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3OEjOYP3IIB"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9), \n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "  metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Facial_Embeddings_Keras_Openface.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
