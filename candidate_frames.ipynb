{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_DIR = \"data\"\n",
    "ANNOTATION_TRAIN_DIR = os.path.join(DATA_DIR, \"annotations/train\")\n",
    "AROUSAL_TRAIN_DIR = os.path.join(DATA_DIR, \"annotations/train/arousal\")\n",
    "VALENCE_TRAIN_DIR = os.path.join(DATA_DIR, \"annotations/train/valence\")\n",
    "AROUSAL_TRAIN_FILES = os.path.join(AROUSAL_TRAIN_DIR, \"*.txt\")\n",
    "VALENCE_TRAIN_FILES = os.path.join(VALENCE_TRAIN_DIR, \"*.txt\")\n",
    "\n",
    "BBOXES_TRAIN_DIR = os.path.join(DATA_DIR, \"bboxs/train\")\n",
    "LANDMARKS_TRAIN_DIR = os.path.join(DATA_DIR, \"landmarks/train\")\n",
    "VIDEOS_TRAIN_DIR = os.path.join(DATA_DIR, \"videos/train\")\n",
    "VIDEOS_TEST_DIR = os.path.join(DATA_DIR, \"videos/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10076\n",
      "10076\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sanity: if the number of annotations same as the number of frames.\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def count_frame(path: str) -> int:\n",
    "    video_obj = cv2.VideoCapture(path)\n",
    "    frame_counter = 0\n",
    "    success = 1\n",
    "    while success:\n",
    "        success, _ = video_obj.read()\n",
    "        frame_counter += 1\n",
    "    return frame_counter - 1\n",
    "\n",
    "def count_lines(path: str) -> int:\n",
    "    line_counter = 0\n",
    "    with open(path) as f:\n",
    "        for _ in f:\n",
    "            line_counter += 1\n",
    "    return line_counter\n",
    "num_frames = count_frame(os.path.join(VIDEOS_TRAIN_DIR, \"105.avi\"))\n",
    "num_annotations = count_lines(os.path.join(AROUSAL_TRAIN_DIR, \"105.txt\"))\n",
    "print(num_frames)\n",
    "print(num_annotations)\n",
    "assert num_frames == num_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4872\n",
      "1008653\n",
      "{2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569, 2570, 2571, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489, 2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2553, 2554, 2555, 2556, 2557, 2558, 2559}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Filter frames by arousal and valence and save to a folder.\n",
    "\"\"\"\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "\n",
    "def is_bored(valence: float, \n",
    "             arousal: float, \n",
    "             radius: float=0.1) -> bool:\n",
    "    \"\"\"\n",
    "    Defined bored in valence, arousal. See Fig. 1 in https://arxiv.org/pdf/1804.10938.pdf.\n",
    "    \"\"\"\n",
    "    bored_valence = -0.34 \n",
    "    bored_arousal = -0.78\n",
    "    return (bored_valence - radius <= valence <= bored_valence + radius and \n",
    "            bored_arousal - radius <= arousal <= bored_arousal + radius)\n",
    "\n",
    "def get_video_path(video_id: str):\n",
    "    mp4_path = os.path.join(VIDEOS_TRAIN_DIR, video_id + \".mp4\")\n",
    "    avi_path = os.path.join(VIDEOS_TRAIN_DIR, video_id + \".avi\")\n",
    "    if os.path.isfile(mp4_path):\n",
    "        return mp4_path\n",
    "    if os.path.isfile(avi_path):\n",
    "        return avi_path\n",
    "    raise ValueError(\"Video {} does not exist\".format(video_id))\n",
    "\n",
    "def create_candidates(output_dir=\"candidates\", radius: float=0.2) -> str:\n",
    "    candidate_frames = defaultdict(set)\n",
    "    total_count = 0\n",
    "    bored_count = 0\n",
    "    for arousal_file, valence_file in zip(sorted(glob.glob(AROUSAL_TRAIN_FILES)), sorted(glob.glob(VALENCE_TRAIN_FILES))):\n",
    "        video_id = os.path.splitext(os.path.basename(arousal_file))[0] # eg. file_id = 105\n",
    "        arousal_file = open(arousal_file, 'r')\n",
    "        valence_file = open(valence_file, 'r')\n",
    "        arousal_values = [float(line) for line in arousal_file.readlines()]\n",
    "        valence_values = [float(line) for line in valence_file.readlines()]\n",
    "        for frame_id, (valence_value, arousal_value) in enumerate(zip(valence_values, arousal_values)):\n",
    "            total_count += 1\n",
    "            if is_bored(valence_value, arousal_value, radius=radius):\n",
    "                bored_count += 1\n",
    "                candidate_frames[video_id].add(frame_id)\n",
    "\n",
    "    # Create frame file for each candidate frames.\n",
    "    output_dir = os.path.join(output_dir, str(radius))\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for video_id, candidate_frames in candidate_frames.items():\n",
    "        video_file = get_video_path(video_id)\n",
    "        video_obj = cv2.VideoCapture(video_file)\n",
    "        frame_id = 0\n",
    "        success = 1\n",
    "        while success:\n",
    "            success, frame = video_obj.read()\n",
    "            if frame_id in candidate_frames:\n",
    "                cv2.imwrite(os.path.join(output_dir, \"{}_{}.jpg\".format(video_id, frame_id)),\n",
    "                            frame)\n",
    "            frame_id += 1\n",
    "\n",
    "    return candidate_frames, bored_count, total_count\n",
    "    \n",
    "    \n",
    "candidate_frames, bored_count, total_count = create_candidates(radius=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Radius = 0.3, annotation. Inclusive range.\n",
    "\"\"\"\n",
    "annotations = [\n",
    "    [\"299_448\", \"299_454\"],\n",
    "    [\"305_1712\", \"305_1760\"],\n",
    "    [\"308_247\", \"308_286\"],\n",
    "    [\"312_1289\", \"312_1329\"],\n",
    "    [\"313_324\", \"313_345\"],\n",
    "    [\"313_1276\", \"313_1625\"],\n",
    "    [\"369_680\", \"369_896\"],\n",
    "    [\"377_2034\", \"377_2234\"], \n",
    "    [\"385_244\", \"385_521\"],\n",
    "    [\"386_84\", \"386_128\"],\n",
    "    [\"389_418\", \"389_3404\"],\n",
    "    [\"400_42\", \"400_72\"],\n",
    "    [\"447_929\", \"447_1118\"],\n",
    "    [\"448_1295\", \"448_2571\"]\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
